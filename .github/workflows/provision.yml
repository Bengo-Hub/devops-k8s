name: Provision Cluster Infrastructure

on:
  push:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      enable_cleanup:
        description: 'Enable cluster cleanup (DANGEROUS - deletes all data). Set to false to disable.'
        required: false
        default: false
        type: boolean

jobs:
  provision:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    env:
      # Configurable domains and IPs via GitHub secrets (with defaults)
      # Priority: GitHub secrets first, fallback to defaults
      ARGOCD_DOMAIN: ${{ secrets.ARGOCD_DOMAIN || 'argocd.masterspace.co.ke' }}
      GRAFANA_DOMAIN: ${{ secrets.GRAFANA_DOMAIN || 'grafana.masterspace.co.ke' }}
      DB_NAMESPACE: ${{ secrets.DB_NAMESPACE || 'infra' }}
      MONITORING_NAMESPACE: ${{ secrets.MONITORING_NAMESPACE || 'infra' }}
      CLUSTER_NAME: ${{ secrets.CLUSTER_NAME || 'mss-prod' }}
      # Cleanup disabled by default (opt-in only)
      ENABLE_CLEANUP: ${{ github.event_name == 'workflow_dispatch'
        && (github.event.inputs.enable_cleanup == 'true' && 'true' || 'false')
        || 'false' }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install DevOps tools (kubectl, helm, yq, argocd)
        uses: ./.github/actions/install-devops-tools
        with:
          install_trivy: 'false'

      - name: Install PostgreSQL client (psql) and jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y postgresql-client postgresql-client-common jq curl

      - name: Get VPS IP and ensure running (via Contabo API)
        id: contabo_vps
        env:
          CONTABO_CLIENT_ID: ${{ secrets.CONTABO_CLIENT_ID }}
          CONTABO_CLIENT_SECRET: ${{ secrets.CONTABO_CLIENT_SECRET }}
          CONTABO_API_USERNAME: ${{ secrets.CONTABO_API_USERNAME }}
          CONTABO_API_PASSWORD: ${{ secrets.CONTABO_API_PASSWORD }}
          CONTABO_INSTANCE_ID: ${{ secrets.CONTABO_INSTANCE_ID || '14285715' }}
          SSH_HOST: ${{ secrets.SSH_HOST || '' }}
        run: |
          echo "::group::Contabo API - VPS Management"
          
          # Priority: SSH_HOST secret > Contabo API
          if [ -n "${SSH_HOST}" ] && [ "${SSH_HOST}" != "YOUR_VPS_IP" ]; then
            echo "‚úÖ Using VPS IP from SSH_HOST secret: ${SSH_HOST}"
            echo "vps_ip=${SSH_HOST}" >> $GITHUB_OUTPUT
            echo "vps_source=github_secret" >> $GITHUB_OUTPUT
            echo "::endgroup::"
            exit 0
          fi
          
          # Check if Contabo API credentials are available
          if [ -z "${CONTABO_CLIENT_ID}" ] || [ -z "${CONTABO_CLIENT_SECRET}" ] || \
             [ -z "${CONTABO_API_USERNAME}" ] || [ -z "${CONTABO_API_PASSWORD}" ]; then
            echo "‚ö†Ô∏è  Contabo API credentials not available"
            echo "‚ö†Ô∏è  Please set SSH_HOST secret with VPS IP address"
            echo "‚ö†Ô∏è  Or configure Contabo API credentials (CONTABO_CLIENT_ID, CONTABO_CLIENT_SECRET, etc.)"
            echo "vps_ip=" >> $GITHUB_OUTPUT
            echo "vps_source=none" >> $GITHUB_OUTPUT
            echo "::endgroup::"
            exit 0
          fi
          
          # Source Contabo API helper
          source ./scripts/tools/contabo-api.sh
          
          # Get access token
          ACCESS_TOKEN=$(get_contabo_token)
          if [ $? -ne 0 ]; then
            echo "‚ùå Failed to get Contabo API token"
            echo "vps_ip=" >> $GITHUB_OUTPUT
            echo "vps_source=none" >> $GITHUB_OUTPUT
            echo "::endgroup::"
            exit 0
          fi
          
          # Ensure VPS is running
          echo "Ensuring VPS is running..."
          ensure_vps_running "$ACCESS_TOKEN"
          
          # Get VPS IP
          VPS_IP=$(get_vps_ip_from_contabo "$ACCESS_TOKEN")
          if [ $? -eq 0 ] && [ -n "$VPS_IP" ]; then
            echo "‚úÖ Got VPS IP from Contabo API: ${VPS_IP}"
            echo "vps_ip=${VPS_IP}" >> $GITHUB_OUTPUT
            echo "vps_source=contabo_api" >> $GITHUB_OUTPUT
          else
            echo "‚ùå Failed to get VPS IP from Contabo API"
            echo "vps_ip=" >> $GITHUB_OUTPUT
            echo "vps_source=none" >> $GITHUB_OUTPUT
          fi
          
          echo "::endgroup::"

      - name: Configure kubeconfig
        id: kubeconfig_setup
        env:
          KUBE_CONFIG_B64: ${{ secrets.KUBE_CONFIG }}
        run: |
          echo "::group::Checking KUBE_CONFIG"
          if [ -z "$KUBE_CONFIG_B64" ]; then
            echo "‚ùå KUBE_CONFIG secret not provided."
            echo ""
            echo "üìã MANUAL SETUP REQUIRED:"
            echo "This workflow requires a Kubernetes cluster to be set up manually first."
            echo "Please follow the manual setup guide: docs/contabo-setup-kubeadm.md"
            echo ""
            echo "After completing manual setup:"
            echo "1. Get your kubeconfig from the VPS: cat ~/.kube/config | base64 -w 0"
            echo "2. Add it as GitHub secret: KUBE_CONFIG"
            echo "3. Re-run this workflow to provision infrastructure"
            echo ""
            echo "skip_provision=true" >> $GITHUB_ENV
            echo "kubeconfig_ready=false" >> $GITHUB_OUTPUT
            echo "::endgroup::"
            exit 0
          fi
          echo "‚úÖ KUBE_CONFIG secret found"
          echo "::endgroup::"
          
          echo "::group::Decoding and configuring kubeconfig"
          mkdir -p ~/.kube
          
          # Clean the base64 string (remove whitespace, newlines, etc.)
          CLEAN_B64=$(echo "$KUBE_CONFIG_B64" | tr -d '[:space:]')
          
          # Validate base64 format
          if ! echo "$CLEAN_B64" | base64 -d >/dev/null 2>&1; then
            echo "‚ùå Invalid base64 format in KUBE_CONFIG secret"
            echo ""
            echo "Troubleshooting:"
            echo "1. Make sure you copied the ENTIRE base64 output from setup-cluster.sh"
            echo "2. The kubeconfig should be base64-encoded WITHOUT line breaks"
            echo "3. To regenerate on VPS: cat /etc/kubernetes/admin.conf | base64 -w 0"
            echo "4. Or: cat ~/.kube/config | base64 -w 0"
            echo ""
            echo "Current secret length: ${#CLEAN_B64} characters"
            echo "First 50 chars: ${CLEAN_B64:0:50}..."
            exit 1
          fi
          
          # Decode and write kubeconfig
          echo "$CLEAN_B64" | base64 -d > ~/.kube/config
          
          # Verify kubeconfig file was created and has content
          if [ ! -s ~/.kube/config ]; then
            echo "‚ùå Kubeconfig file is empty after decoding"
            exit 1
          fi
          
          chmod 600 ~/.kube/config
          echo "‚úÖ Kubeconfig written to ~/.kube/config ($(wc -c < ~/.kube/config) bytes)"
          echo "::endgroup::"
          
          echo "::group::Testing cluster connectivity"
          if kubectl cluster-info >/dev/null 2>&1; then
            echo "‚úÖ Successfully connected to Kubernetes cluster"
            kubectl get nodes || true
            
            # Check if cluster is ready for provisioning
            READY_NODES=$(kubectl get nodes --no-headers 2>/dev/null | grep -c "Ready" || echo "0")
            if [ "$READY_NODES" -gt 0 ]; then
              echo "‚úÖ Cluster is ready (${READY_NODES} node(s) Ready)"
              echo "skip_provision=false" >> $GITHUB_ENV
              echo "kubeconfig_ready=true" >> $GITHUB_OUTPUT
            else
              echo "‚ö†Ô∏è  No Ready nodes found. Cluster may not be fully initialized."
              echo "skip_provision=false" >> $GITHUB_ENV
              echo "kubeconfig_ready=true" >> $GITHUB_OUTPUT
            fi
          else
            echo "‚ùå Failed to connect to cluster. Check your KUBE_CONFIG."
            echo "skip_provision=true" >> $GITHUB_ENV
            echo "kubeconfig_ready=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "::endgroup::"

      - name: Ensure scripts executable
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        run: |
          chmod +x scripts/**/*.sh || true
          chmod +x scripts/*/*.sh || true

      - name: Check cluster health and readiness
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        run: |
          echo "::group::Cluster Health Check"
          echo "Checking cluster status..."
          
          # Check nodes
          kubectl get nodes || true
          READY_NODES=$(kubectl get nodes --no-headers 2>/dev/null | grep -c "Ready" || echo "0")
          TOTAL_NODES=$(kubectl get nodes --no-headers 2>/dev/null | wc -l || echo "0")
          
          if [ "$READY_NODES" -eq 0 ] && [ "$TOTAL_NODES" -gt 0 ]; then
            echo "‚ö†Ô∏è  Warning: Cluster has nodes but none are Ready"
            echo "This may indicate CNI or other initialization issues"
          elif [ "$READY_NODES" -gt 0 ]; then
            echo "‚úÖ Cluster is healthy (${READY_NODES}/${TOTAL_NODES} nodes Ready)"
          fi
          
          # Check for Pending pods
          PENDING_COUNT=$(kubectl get pods -A --field-selector=status.phase=Pending --no-headers 2>/dev/null | wc -l || echo "0")
          if [ "$PENDING_COUNT" -gt 0 ]; then
            echo "‚ö†Ô∏è  Warning: Found $PENDING_COUNT Pending pods"
            echo "Running diagnostics..."
            if [ -f ./scripts/diagnostics/diagnose-pending-pods.sh ]; then
              chmod +x ./scripts/diagnostics/diagnose-pending-pods.sh
              ./scripts/diagnostics/diagnose-pending-pods.sh || true
            fi
          else
            echo "‚úÖ No Pending pods found"
          fi
          
          # Check for CrashLoopBackOff pods
          CRASHING_COUNT=$(kubectl get pods -A --field-selector=status.phase=Failed --no-headers 2>/dev/null | wc -l || echo "0")
          if [ "$CRASHING_COUNT" -gt 0 ]; then
            echo "‚ö†Ô∏è  Warning: Found $CRASHING_COUNT Failed pods"
            kubectl get pods -A --field-selector=status.phase=Failed 2>/dev/null | head -5 || true
          fi
          
          echo "::endgroup::"

      - name: Check and optimize etcd space (prevent space issues)
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        run: |
          echo "::group::Checking and Optimizing etcd Space"
          
          # Check etcd space before provisioning (prevent space exceeded errors)
          if [ -f ./scripts/cluster/check-etcd-space.sh ]; then
            echo "Checking etcd space status..."
            chmod +x ./scripts/cluster/check-etcd-space.sh
            ./scripts/cluster/check-etcd-space.sh || echo "‚ö†Ô∏è  etcd check completed"
          else
            echo "‚ö†Ô∏è  etcd check script not found - skipping space check"
          fi
          
          # Run fix script if space issues detected (idempotent - only fixes if needed)
          if [ -f ./scripts/cluster/fix-etcd-space.sh ]; then
            echo "Running preventive etcd maintenance (if needed)..."
            chmod +x ./scripts/cluster/fix-etcd-space.sh
            ./scripts/cluster/fix-etcd-space.sh || echo "‚ö†Ô∏è  etcd maintenance completed"
          else
            echo "‚ö†Ô∏è  etcd fix script not found - skipping preventive maintenance"
            echo "‚ö†Ô∏è  If you encounter 'database space exceeded' errors, configure auto-compaction"
            echo "‚ö†Ô∏è  See: docs/ETCD-OPTIMIZATION.md"
          fi
          
          echo "‚úÖ etcd space check complete"
          echo "::endgroup::"

      - name: Cleanup cluster (opt-in only)
        if: ${{ steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true' && env.ENABLE_CLEANUP == 'true' }}
        env:
          ENABLE_CLEANUP: ${{ env.ENABLE_CLEANUP }}
          FORCE_CLEANUP: 'true'
        run: |
          echo "::group::Cluster Cleanup"
          echo "ENABLE_CLEANUP=${ENABLE_CLEANUP}"
          echo "üßπ Cleanup is ENABLED - This will delete ALL applications and data!"
          echo "‚ö†Ô∏è  Deleting namespaces: erp, truload, infra, argocd, monitoring, cafe, treasury, notifications, auth-service"
          echo "‚ö†Ô∏è  System namespaces preserved: kube-system, calico-system, cert-manager, ingress-nginx"
          export ENABLE_CLEANUP=true
          export FORCE_CLEANUP=true
          ./scripts/cluster/cleanup-cluster.sh
          echo "‚úÖ Cleanup complete"
          echo "::endgroup::"

      - name: Install storage provisioner (idempotent)
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        timeout-minutes: 10
        run: |
          echo "::group::Installing Storage Provisioner"
          echo "This step is required before installing databases (for PVCs)"
          ./scripts/infrastructure/install-storage-provisioner.sh
          echo "‚úÖ Storage provisioner installed"
          echo "::endgroup::"

      - name: Install databases (PostgreSQL & Redis - Shared Infrastructure)
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        timeout-minutes: 20
        env:
          # Priority: GitHub secrets first, fallback to auto-generated
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD || '' }}
          POSTGRES_ADMIN_PASSWORD: ${{ secrets.POSTGRES_ADMIN_PASSWORD || secrets.POSTGRES_PASSWORD || '' }}
          REDIS_PASSWORD: ${{ secrets.REDIS_PASSWORD || '' }}
          DB_NAMESPACE: ${{ env.DB_NAMESPACE }}
          ENABLE_CLEANUP: ${{ env.ENABLE_CLEANUP }}
        run: |
          echo "::group::Installing Shared Databases (PostgreSQL & Redis in ${DB_NAMESPACE} namespace)"
          echo "Installing shared infrastructure databases..."
          echo "Namespace: ${DB_NAMESPACE}"
          echo "PostgreSQL will create admin_user for managing per-service databases"
          echo "Note: This may take 10-15 minutes for first installation"
          export NAMESPACE=${DB_NAMESPACE}
          export PG_DATABASE=postgres
          ./scripts/infrastructure/install-databases.sh
          echo "‚úÖ Shared databases installed in ${DB_NAMESPACE} namespace"
          echo "‚úÖ PostgreSQL admin_user created (can create per-service databases)"
          echo "‚úÖ Each service will create its own database during deployment"
          echo "::endgroup::"
      
      - name: Install RabbitMQ (Shared Infrastructure)
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        timeout-minutes: 15
        env:
          # Priority: GitHub secrets first, fallback to default
          RABBITMQ_PASSWORD: ${{ secrets.RABBITMQ_PASSWORD || 'rabbitmq' }}
          RABBITMQ_NAMESPACE: ${{ env.DB_NAMESPACE }}
          ENABLE_CLEANUP: ${{ env.ENABLE_CLEANUP }}
        run: |
          echo "::group::Installing RabbitMQ (Shared Infrastructure in ${RABBITMQ_NAMESPACE} namespace)"
          echo "Installing RabbitMQ as shared infrastructure..."
          echo "Namespace: ${RABBITMQ_NAMESPACE}"
          echo "Note: This may take 5-10 minutes"
          ./scripts/infrastructure/install-rabbitmq.sh
          echo "‚úÖ RabbitMQ installed in ${RABBITMQ_NAMESPACE} namespace"
          echo "‚úÖ All services can use shared RabbitMQ instance"
          echo "::endgroup::"

      - name: Configure ingress controller (idempotent)
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        timeout-minutes: 10
        run: |
          echo "::group::Configuring NGINX Ingress Controller"
          echo "Installing NGINX Ingress Controller (required for cert-manager and ArgoCD)"
          ./scripts/infrastructure/configure-ingress-controller.sh
          echo "‚úÖ Ingress controller configured"
          echo "::endgroup::"

      - name: Install cert-manager (idempotent)
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        timeout-minutes: 10
        run: |
          echo "::group::Installing cert-manager"
          echo "Installing cert-manager for TLS certificates (required for ArgoCD and monitoring)"
          ./scripts/infrastructure/install-cert-manager.sh
          echo "‚úÖ cert-manager installed"
          echo "::endgroup::"

      - name: Install Argo CD (idempotent)
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        timeout-minutes: 15
        env:
          ARGOCD_DOMAIN: ${{ env.ARGOCD_DOMAIN }}
        run: |
          echo "::group::Installing Argo CD"
          echo "Installing ArgoCD GitOps tool (requires cert-manager for TLS)"
          ./scripts/infrastructure/install-argocd.sh
          echo "‚úÖ ArgoCD installed"
          echo "::endgroup::"

      - name: Bootstrap Argo CD applications (app-of-apps)
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        run: |
          echo "::group::Bootstrapping Argo CD applications"
          # Apply the root Application that manages apps under apps/
          if [ -f apps/root-app.yaml ]; then
            kubectl apply -f apps/root-app.yaml
            echo "‚úÖ root Application applied"
          else
            echo "‚ö†Ô∏è apps/root-app.yaml not found; skipping"
          fi
          
          # Also apply individual applications directly to ensure they're created
          echo "Applying individual ArgoCD Applications..."
          for app_file in apps/*/app.yaml; do
            if [ -f "$app_file" ]; then
              kubectl apply -f "$app_file" || echo "‚ö†Ô∏è Failed to apply $app_file"
              echo "‚úì Applied: $app_file"
            fi
          done
          
          echo "Current ArgoCD Applications:"
          kubectl get applications -n argocd || true
          echo "::endgroup::"

      - name: Install Monitoring (idempotent)
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        timeout-minutes: 20
        env:
          GRAFANA_DOMAIN: ${{ env.GRAFANA_DOMAIN }}
          MONITORING_NAMESPACE: ${{ env.MONITORING_NAMESPACE }}
          ENABLE_CLEANUP: ${{ env.ENABLE_CLEANUP }}
        run: |
          echo "::group::Installing Monitoring Stack"
          echo "Installing Prometheus + Grafana monitoring stack"
          echo "Note: This may take 10-15 minutes"
          ./scripts/monitoring/install-monitoring.sh
          echo "‚úÖ Monitoring stack installed"
          echo "::endgroup::"

      - name: Install Vertical Pod Autoscaler (VPA)
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        timeout-minutes: 10
        run: |
          echo "::group::Installing Vertical Pod Autoscaler"
          echo "Installing VPA for automatic pod resource optimization"
          ./scripts/infrastructure/install-vpa.sh
          echo "‚úÖ VPA installed"
          echo "::endgroup::"

      - name: Setup Git Access (SSH Keys & Configuration)
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        run: |
          echo "::group::Setting up Git SSH Access"
          echo "‚ö†Ô∏è  Note: Git SSH access setup is optional and requires manual GitHub deploy key configuration"
          echo "This step generates a key pair, but you must manually add the public key to GitHub"
          echo ""
          
          # Create SSH directory if it doesn't exist
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          
          # Generate SSH key pair for git operations (if not exists)
          if [ ! -f ~/.ssh/git_deploy_key ]; then
            echo "üîë Generating SSH key pair for git operations..."
            ssh-keygen -t ed25519 -C "vps-git-access@bengoerp" -f ~/.ssh/git_deploy_key -N ""
            chmod 600 ~/.ssh/git_deploy_key
            chmod 644 ~/.ssh/git_deploy_key.pub
          else
            echo "‚úÖ SSH key pair already exists"
          fi
          
          # Add GitHub to known hosts
          ssh-keyscan github.com >> ~/.ssh/known_hosts 2>/dev/null || true
          
          # Create SSH config for reliable git operations
          cat > ~/.ssh/config << 'EOF'
          Host github.com
              HostName github.com
              User git
              IdentityFile ~/.ssh/git_deploy_key
              IdentitiesOnly yes
              StrictHostKeyChecking no
          EOF
          chmod 600 ~/.ssh/config
          
          # Display public key for deploy key setup
          echo ""
          echo "üîë PUBLIC KEY FOR GITHUB DEPLOY KEY (MANUAL SETUP REQUIRED):"
          echo "============================================================="
          cat ~/.ssh/git_deploy_key.pub
          echo "============================================================="
          echo ""
          echo "üìã MANUAL STEPS:"
          echo "1. Copy the public key above"
          echo "2. Go to: https://github.com/Bengo-Hub/devops-k8s/settings/keys"
          echo "3. Add deploy key with 'Allow write access' enabled"
          echo "4. Test: git clone git@github.com:Bengo-Hub/devops-k8s.git"
          echo ""
          
          echo "::endgroup::"
      
      - name: Summary
        if: steps.kubeconfig_setup.outputs.kubeconfig_ready == 'true'
        env:
          ARGOCD_DOMAIN: ${{ env.ARGOCD_DOMAIN }}
          GRAFANA_DOMAIN: ${{ env.GRAFANA_DOMAIN }}
          DB_NAMESPACE: ${{ env.DB_NAMESPACE }}
        run: |
          echo "::group::Cluster Infrastructure Provisioning Complete"
          echo ""
          echo "‚úÖ Storage provisioner installed"
          echo "‚úÖ Shared Databases installed (PostgreSQL & Redis in ${DB_NAMESPACE} namespace)"
          echo "  - PostgreSQL admin_user created for managing per-service databases"
          echo "  - Each service creates its own database during deployment"
          echo "‚úÖ RabbitMQ installed (shared infrastructure in ${DB_NAMESPACE} namespace)"
          echo "‚úÖ NGINX Ingress Controller configured"
          echo "‚úÖ cert-manager installed"
          echo "‚úÖ Argo CD installed (https://${ARGOCD_DOMAIN})"
          echo "‚úÖ Monitoring Stack installed (https://${GRAFANA_DOMAIN}) in ${DB_NAMESPACE} namespace"
          echo "‚úÖ Vertical Pod Autoscaler (VPA) installed"
          echo ""
          echo "Shared Infrastructure Credentials (${DB_NAMESPACE} namespace):"
          echo "- PostgreSQL admin_user: kubectl get secret postgresql -n ${DB_NAMESPACE} -o jsonpath='{.data.admin-user-password}' | base64 -d"
          echo "- PostgreSQL postgres user: kubectl get secret postgresql -n ${DB_NAMESPACE} -o jsonpath='{.data.postgres-password}' | base64 -d"
          echo "- Redis: kubectl get secret redis -n ${DB_NAMESPACE} -o jsonpath='{.data.redis-password}' | base64 -d"
          echo "- RabbitMQ: kubectl get secret rabbitmq -n ${DB_NAMESPACE} -o jsonpath='{.data.rabbitmq-password}' | base64 -d"
          echo ""
          echo "Per-Service Databases:"
          echo "- Each service (cafe-backend, erp-api, treasury-app, notifications-app) creates its own database"
          echo "- Database names: cafe, bengo_erp, treasury, notifications"
          echo "- Databases are created automatically during service deployment"
          echo ""
          echo "Configuration (via GitHub Secrets - priority order):"
          echo "- ARGOCD_DOMAIN: ${ARGOCD_DOMAIN} (from secrets.ARGOCD_DOMAIN or default)"
          echo "- GRAFANA_DOMAIN: ${GRAFANA_DOMAIN} (from secrets.GRAFANA_DOMAIN or default)"
          echo "- DB_NAMESPACE: ${DB_NAMESPACE} (from secrets.DB_NAMESPACE or default)"
          echo ""
          echo "Next steps:"
          echo "1. Set up GitHub deploy key (see Git SSH Access step above - manual setup required)"
          echo "2. Point DNS to your VPS IP"
          echo "3. Configure Argo CD repository access"
          echo "4. Deploy applications via Argo CD (they will auto-create databases)"
          echo "5. Verify databases: kubectl -n ${DB_NAMESPACE} exec -it postgresql-0 -- psql -U admin_user -d postgres -c '\l'"
          echo "6. Verify VPA: kubectl get vpa --all-namespaces"
          echo ""
          echo "üìö Documentation:"
          echo "- Manual VPS setup: docs/VPS-MANUAL-SETUP.md"
          echo "- GitHub secrets: docs/github-secrets.md"
          echo "- Provisioning guide: docs/provisioning.md"
          echo "::endgroup::"

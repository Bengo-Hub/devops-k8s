---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: pod-cleanup
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pod-cleanup
rules:
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "list", "delete"]
  - apiGroups: [""]
    resources: ["namespaces"]
    verbs: ["get", "list"]
  - apiGroups: ["apps"]
    resources: ["deployments", "replicasets"]
    verbs: ["get", "list", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: pod-cleanup
subjects:
  - kind: ServiceAccount
    name: pod-cleanup
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: pod-cleanup
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: cleanup-failed-pods
  namespace: kube-system
spec:
  # Run every 30 minutes
  schedule: "*/30 * * * *"
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  concurrencyPolicy: Forbid
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: pod-cleanup
        spec:
          serviceAccountName: pod-cleanup
          restartPolicy: OnFailure
          containers:
            - name: cleanup
              image: bitnami/kubectl:latest
              imagePullPolicy: IfNotPresent
              command:
                - /bin/bash
                - -c
                - |
                  #!/bin/bash
                  set -euo pipefail
                  
                  echo "üßπ Starting automated pod cleanup at $(date)"
                  
                  # Define namespaces to scan (exclude kube-system, kube-public, kube-node-lease)
                  EXCLUDE_NS="kube-system|kube-public|kube-node-lease|calico-system|calico-apiserver|argocd"
                  NAMESPACES=$(kubectl get namespaces -o jsonpath='{.items[*].metadata.name}' | tr ' ' '\n' | grep -vE "^($EXCLUDE_NS)$" || true)
                  
                  TOTAL_DELETED=0
                  
                  # Function to delete pods by status phase with optional age threshold
                  cleanup_by_phase() {
                    local PHASE=$1
                    local AGE_THRESHOLD=${2:-0}  # Age threshold in seconds (0 = delete immediately)
                    echo "üîç Scanning for pods in $PHASE state (threshold: ${AGE_THRESHOLD}s)..."
                    
                    for NS in $NAMESPACES; do
                      if [ $AGE_THRESHOLD -eq 0 ]; then
                        # Delete all pods in this phase immediately
                        PODS=$(kubectl get pods -n "$NS" --field-selector=status.phase="$PHASE" -o jsonpath='{.items[*].metadata.name}' 2>/dev/null || echo "")
                      else
                        # Only delete pods older than threshold using jq
                        PODS=$(kubectl get pods -n "$NS" --field-selector=status.phase="$PHASE" -o json 2>/dev/null | \
                          jq -r --arg threshold "$AGE_THRESHOLD" '.items[] | select((.metadata.creationTimestamp | fromdateiso8601) < (now - ($threshold | tonumber))) | .metadata.name' 2>/dev/null || echo "")
                      fi
                      
                      if [ -n "$PODS" ]; then
                        echo "  üì¶ Deleting $PHASE pods in namespace $NS"
                        for POD in $PODS; do
                          echo "    ‚úì Deleting: $POD"
                          kubectl delete pod -n "$NS" "$POD" --grace-period=0 --force 2>/dev/null || true
                          TOTAL_DELETED=$((TOTAL_DELETED + 1))
                        done
                      fi
                    done
                  }
                  
                  # Function to prevent recreation of failed pods by scaling down failed deployments
                  disable_failed_deployments() {
                    echo "üîç Scanning for deployments with repeated pod failures..."
                    
                    for NS in $NAMESPACES; do
                      # Find deployments where all pods are failing (0 ready replicas)
                      FAILED_DEPLOYS=$(kubectl get deployments -n "$NS" -o json 2>/dev/null | \
                        jq -r '.items[] | select(.status.replicas > 0 and .status.readyReplicas == 0 and .status.replicas == .status.unavailableReplicas) | .metadata.name' 2>/dev/null || echo "")
                      
                      if [ -n "$FAILED_DEPLOYS" ]; then
                        for DEPLOY in $FAILED_DEPLOYS; do
                          # Check if deployment has been failing for >10 minutes using jq date math
                          STATUS=$(kubectl get deployment -n "$NS" "$DEPLOY" -o json 2>/dev/null | \
                            jq -r 'if (.metadata.creationTimestamp | fromdateiso8601) < (now - 600) then "old" else "new" end' 2>/dev/null || echo "unknown")
                          
                          if [ "$STATUS" = "old" ]; then
                            echo "  ‚è∏Ô∏è  Scaling down failed deployment $NS/$DEPLOY (failing >10min)"
                            kubectl scale deployment -n "$NS" "$DEPLOY" --replicas=0 2>/dev/null || true
                            kubectl annotate deployment -n "$NS" "$DEPLOY" \
                              "bengobox.dev/auto-disabled=true" \
                              "bengobox.dev/disabled-reason=repeated-pod-failures" \
                              "bengobox.dev/disabled-at=$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
                              --overwrite 2>/dev/null || true
                          fi
                        done
                      fi
                    done
                  }
                  
                  # Cleanup immediately: Failed pods (stuck or crashed)
                  cleanup_by_phase "Failed" 0
                  
                  # Cleanup with delay: Pending pods older than 5 minutes (300 seconds)
                  cleanup_by_phase "Pending" 300
                  
                  # Disable deployments with repeated failures
                  disable_failed_deployments
                  
                  # Cleanup completed Jobs older than 1 hour
                  echo "üîç Cleaning up old completed jobs..."
                  for NS in $NAMESPACES; do
                    OLD_JOBS=$(kubectl get jobs -n "$NS" -o json 2>/dev/null | \
                      jq -r '.items[] | select(.status.succeeded == 1 and (.status.completionTime | fromdateiso8601) < (now - 3600)) | .metadata.name' 2>/dev/null || echo "")
                    
                    if [ -n "$OLD_JOBS" ]; then
                      for JOB in $OLD_JOBS; do
                        echo "  üóëÔ∏è  Deleting completed job: $NS/$JOB"
                        kubectl delete job -n "$NS" "$JOB" --cascade=background 2>/dev/null || true
                      done
                    fi
                  done
                  
                  echo "‚úÖ Cleanup completed at $(date)"
                  echo "   Total pods deleted: $TOTAL_DELETED"
                  
                  # Check current pod count
                  RUNNING_PODS=$(kubectl get pods --all-namespaces --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l || echo "0")
                  TOTAL_PODS=$(kubectl get pods --all-namespaces --no-headers 2>/dev/null | wc -l || echo "0")
                  echo "   Current pod status: $RUNNING_PODS Running / $TOTAL_PODS Total (limit: 110)"
                  
                  if [ "$TOTAL_PODS" -ge 100 ]; then
                    echo "‚ö†Ô∏è  WARNING: Cluster approaching pod limit ($TOTAL_PODS/110)"
                  fi
              resources:
                requests:
                  cpu: 10m
                  memory: 32Mi
                limits:
                  cpu: 100m
                  memory: 128Mi

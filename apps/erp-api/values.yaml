image:
  repository: docker.io/codevertex/erp-api
  tag: 588fe16b
  pullSecrets:
    - name: registry-credentials
service:
  port: 80
  targetPort: 4000
# Health check configuration for Django API
# Adjusted for migration execution time (can take 5-10 minutes on first deploy)
healthCheck:
  enabled: true
  startup:
    httpGet:
      path: /api/v1/core/health/
      port: http
    # Allow plenty of time for cold starts, migrations, cache warmup
    initialDelaySeconds: 300 # Increased to 5 minutes
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 30
  readiness:
    httpGet:
      path: /api/v1/core/health/
      port: http
    initialDelaySeconds: 600 # Increased to 10 minutes - migrations take time
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 10 # Increased - allow time for migrations
  liveness:
    httpGet:
      path: /api/v1/core/health/
      port: http
    initialDelaySeconds: 900 # Increased to 15 minutes - migrations can take 5-10 min
    periodSeconds: 60
    timeoutSeconds: 15
    failureThreshold: 5
# Production resource limits for Django API with large ERP schema
# This app requires high memory due to:
# - 30+ Django apps with complex models
# - Heavy migrations (300+ tables)
# - Real-time WebSocket connections
# - Async task processing
resources:
  requests:
    cpu: 500m # Priority business application
    memory: 3Gi # Required for Django ORM with large schema + migrations
  limits:
    cpu: 3000m
    memory: 6Gi # Peak memory for migrations and heavy queries
# Horizontal autoscaling based on CPU and memory
autoscaling:
  enabled: true
  minReplicas: 2 # Minimum 2 for high availability
  maxReplicas: 4 # Scale up to 4 replicas under load
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 75
  scaleDown:
    stabilizationWindowSeconds: 300
    policies:
      - type: Percent
        value: 50
        periodSeconds: 60
  scaleUp:
    stabilizationWindowSeconds: 60
    policies:
      - type: Percent
        value: 100
        periodSeconds: 30
ingress:
  enabled: true
  ingressClassName: nginx
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    # WebSocket support for Django Channels (payroll real-time updates)
    nginx.ingress.kubernetes.io/websocket-services: erp-api-app
    nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
    # Serve media files directly from Django (for production media serving)
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/configuration-snippet: |
      location /media/ {
        proxy_pass http://erp-api-app.erp.svc.cluster.local:80;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
      }
      location /static/ {
        proxy_pass http://erp-api-app.erp.svc.cluster.local:80;
        proxy_set_header Host $host;
      }
  hosts:
    - host: erpapi.masterspace.co.ke
      paths:
        - path: /
          pathType: Prefix
  tls:
    - hosts:
        - erpapi.masterspace.co.ke
      secretName: erpapi-masterspace-tls
envFromSecret: erp-api-env
# ============================================================================
# MIGRATIONS AND SEEDING
# ============================================================================
# ERP-API Django migrations strategy:
# 1. Database check runs in initContainer (wait-for-db)
# 2. Migrations run automatically in entrypoint.sh on first pod startup
# 3. Subsequent pods skip migrations if already applied (idempotent)
# 4. Heavy migrations (300+ tables) require 3-6Gi memory
migrations:
  enabled: false # Use app's built-in migration handling via entrypoint.sh
  runOnStartup: true # Enable initContainer for database connectivity check
  resources:
    requests:
      cpu: 500m # Migrations are CPU-intensive
      memory: 3Gi # Required for Django migration executor with large schema
    limits:
      cpu: 2000m
      memory: 6Gi # Peak memory during migration execution
# Seeding configuration
seed:
  enabled: true # Enable seed data creation via Django management command
  command: "python manage.py seed_data" # Custom management command for initial data
  runAfterMigrations: true # Run seeds only after migrations complete
  resources:
    requests:
      cpu: 200m
      memory: 512Mi
    limits:
      cpu: 1000m
      memory: 1Gi
# ServiceMonitor configuration (requires Prometheus Operator)
serviceMonitor:
  enabled: false # Disabled - Prometheus Operator CRDs not installed
  namespace: infra
  interval: 30s
  scrapeTimeout: 10s
  labels:
    release: prometheus
# Persistent storage for media uploads
persistence:
  enabled: true
  size: 20Gi
  mountPath: /app/media
  accessMode: ReadWriteOnce
  storageClass: local-path
# Enhanced HPA with custom metrics
autoscalingCustomMetrics:
  enabled: false # Disabled - using basic HPA for now
  # Custom metrics for intelligent scaling (requires metrics adapter)
  customMetrics:
    - type: Pods
      metricName: bengoerp_api_http_requests_per_second
      targetType: AverageValue
      targetAverageValue: 50
    - type: Pods
      metricName: bengoerp_api_db_query_duration_seconds
      targetType: AverageValue
      targetAverageValue: 1.0
    - type: Pods
      metricName: bengoerp_api_active_users
      targetType: AverageValue
      targetAverageValue: 100
# Production-ready VPA configuration (DISABLED to prevent pod evictions during migrations)
verticalPodAutoscaling:
  enabled: false # DISABLED - VPA was causing pod evictions during migrations
  updateMode: "Off" # Off to prevent disruption
  minCPU: 500m
  maxCPU: 3000m
  minMemory: 3Gi
  maxMemory: 6Gi
  controlledResources: ["cpu", "memory"]
  controlledValues: RequestsAndLimits
  recommendationMode: false # Apply recommendations automatically in production
# Celery Worker configuration for async task processing
celeryWorker:
  enabled: true
  replicaCount: 1
  app: ProcureProKEAPI
  logLevel: info
  concurrency: 4 # Optimized for 12-core server
  maxTasksPerChild: 100
  resources:
    requests:
      cpu: 300m # Increased for better task processing
      memory: 1Gi # Increased - workers load Django models
    limits:
      cpu: 1500m
      memory: 2Gi
  livenessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 60
    timeoutSeconds: 10
    failureThreshold: 3
# Celery Beat scheduler for periodic tasks
celeryBeat:
  enabled: true
  app: ProcureProKEAPI
  logLevel: info
  scheduler: django_celery_beat.schedulers:DatabaseScheduler
  resources:
    requests:
      cpu: 100m
      memory: 256Mi
    limits:
      cpu: 500m
      memory: 512Mi
  persistence:
    enabled: false
